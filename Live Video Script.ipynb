{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a455004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 307a88f93 Python-3.10.7 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20893344 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this script, we will\n",
    "\"\"\"\n",
    "\n",
    "import torch \n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sort import sort\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\"\"\"\n",
    "Load the model with a certain confidence threshold (TBD)\n",
    "\"\"\"\n",
    "model = torch.hub.load('.','custom','best.pt',source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e88161",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conf = .27 #Minimum .5 confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad68d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "1) Live Video\n",
    "\"\"\"\n",
    "count_list = []\n",
    "frameRate = 0\n",
    "time_limit = 100#10 Seconds\n",
    "vid = cv2.VideoCapture(0)\n",
    "ret,frame = vid.read()\n",
    "image_frames = []\n",
    "\n",
    "#Store tracking info per video\n",
    "tracker=sort.Sort() \n",
    "ids = defaultdict(set)\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bece385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.ttf file, font-size\n",
    "myFont = ImageFont.truetype('ostrich-regular.ttf', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a1f6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8173792362213135 0.35493979196822867\n"
     ]
    }
   ],
   "source": [
    "\"\"\"start_time = time()\n",
    "ret,frame = vid.read()\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGBA)\n",
    "results = model(frame)\n",
    "time_elaps = time()-start_time\n",
    "fps = 1/time_elaps\n",
    "print(time_elaps,fps)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c6a60e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame rate:  0.18555504276747012\n",
      "Final Count list: [0]\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "#Set number of frames to look at for testing purposes\n",
    "while(ret):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    results = model(frame)\n",
    "    #Retrieving boundingbox data as dataframe \n",
    "    #Dataframe Format (xyxy attribute):\n",
    "    #(xmin,ymin,xmax,ymax,confidence,label_value,label)\n",
    "    data = results.pandas().xyxy[0]        \n",
    "    trafficType=data[\"name\"]\n",
    "    data = data.iloc[:][:5].to_numpy()\n",
    "    data = data[:,:5].astype('float64')\n",
    "\n",
    "\n",
    "    #Updated with ids on the camera\n",
    "    track_res = tracker.update(data)\n",
    "\n",
    "    if(track_res.size!=0):\n",
    "        for index,detection in enumerate(track_res[::-1]):\n",
    "            #If the detection is new, add the ID to the\n",
    "            #appropriate vehicle/pedestrian set\n",
    "            #COUNT=LENGTH\n",
    "            if(detection[-1] not in ids[trafficType[index]]):\n",
    "                ids[trafficType[index]].add(detection[-1])\n",
    "\n",
    "    #Image WITH BOX PREDICTIONS AND COUNT\n",
    "    im = Image.fromarray(results.render(labels=False)[0])\n",
    "\n",
    "    #Draw the count on the video frame\n",
    "    im_draw = ImageDraw.Draw(im)\n",
    "    draw_text=\"\"\n",
    "    for trafficType, id_set in ids.items():\n",
    "        draw_text+=trafficType+\" COUNT=\" +str(len(id_set))+\"\\n\"\n",
    "\n",
    "    im_draw.multiline_text((0,\n",
    "                      0), \n",
    "                 draw_text,\n",
    "                 fill='white',font=myFont,\n",
    "                 anchor = None, spacing = 0,\n",
    "                 align=\"left\",direction=None,\n",
    "                 features=None,language=None,\n",
    "                 stroke_width=1, stroke_fill=\"black\")\n",
    "    #Check if the images are being properly converted:\n",
    "    image_frames.append(im)#Append for conversion to video\n",
    "    time_elaps = time()-start_time\n",
    "    if(time_elaps>time_limit):\n",
    "        frameRate = len(image_frames)/(time_elaps)\n",
    "        break\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "#Save video as gif\n",
    "if(len(image_frames)>0):\n",
    "        #Save video as gif\n",
    "        image_frames[0].save('runs/detect/videos/video1.gif',\n",
    "                         save_all=True, optimize=False,append_images=image_frames[1:],loop=0)\n",
    "else:\n",
    "    print(\"No image frames to save!\")\n",
    "\n",
    "#Cars/Pedestrians counted    \n",
    "count_list.append(count)\n",
    "    \n",
    "print(\"Frame rate: \",frameRate)\n",
    "print(\"Final Count list:\", count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

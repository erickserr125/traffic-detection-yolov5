{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a455004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "YOLOv5 ðŸš€ 163666e80 Python-3.8.10 torch-1.13.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20893344 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this script, we will\n",
    "\"\"\"\n",
    "\n",
    "import torch \n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sort import sort\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\"\"\"\n",
    "Load the model with a certain confidence threshold (TBD)\n",
    "\"\"\"\n",
    "model = torch.hub.load('.','custom','best.pt',source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94e88161",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conf = .27 #Minimum .5 confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad68d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initializing values for tracking and video capture:\n",
    "\"\"\"\n",
    "frameRate = 0\n",
    "time_limit = 100#10 Seconds\n",
    "vid = cv2.VideoCapture(0)\n",
    "ret,frame = vid.read()\n",
    "image_frames = []\n",
    "\n",
    "#Store tracking info per video\n",
    "tracker=sort.Sort() \n",
    "ids = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bece385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.ttf file, font-size\n",
    "myFont = ImageFont.truetype('ostrich-regular.ttf', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c6a60e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo image frames to save!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#Cars/Pedestrians counted    \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mcount_list\u001b[49m\u001b[38;5;241m.\u001b[39mappend(count)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame rate: \u001b[39m\u001b[38;5;124m\"\u001b[39m,frameRate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_list' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "#Set number of frames to look at for testing purposes\n",
    "while(ret):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    results = model(frame)\n",
    "    #Retrieving boundingbox data as dataframe \n",
    "    #Dataframe Format (xyxy attribute):\n",
    "    #(xmin,ymin,xmax,ymax,confidence,label_value,label)\n",
    "    data = results.pandas().xyxy[0]        \n",
    "    trafficType=data[\"name\"]\n",
    "    data = data.iloc[:][:5].to_numpy()\n",
    "    data = data[:,:5].astype('float64')\n",
    "\n",
    "\n",
    "    #Updated with ids on the camera\n",
    "    track_res = tracker.update(data)\n",
    "\n",
    "    if(track_res.size!=0):\n",
    "        for index,detection in enumerate(track_res[::-1]):\n",
    "            #If the detection is new, add the ID to the\n",
    "            #appropriate vehicle/pedestrian set\n",
    "            #COUNT=LENGTH\n",
    "            if(detection[-1] not in ids[trafficType[index]]):\n",
    "                ids[trafficType[index]].add(detection[-1])\n",
    "\n",
    "    #Image WITH BOX PREDICTIONS AND COUNT\n",
    "    im = Image.fromarray(results.render(labels=False)[0])\n",
    "\n",
    "    #Draw the count on the video frame\n",
    "    im_draw = ImageDraw.Draw(im)\n",
    "    draw_text=\"\"\n",
    "    for trafficType, id_set in ids.items():\n",
    "        draw_text+=trafficType+\" COUNT=\" +str(len(id_set))+\"\\n\"\n",
    "\n",
    "    im_draw.multiline_text((0,\n",
    "                      0), \n",
    "                 draw_text,\n",
    "                 fill='white',font=myFont,\n",
    "                 anchor = None, spacing = 0,\n",
    "                 align=\"left\",direction=None,\n",
    "                 features=None,language=None,\n",
    "                 stroke_width=1, stroke_fill=\"black\")\n",
    "    #Check if the images are being properly converted:\n",
    "    image_frames.append(im)#Append for conversion to video\n",
    "    time_elaps = time()-start_time\n",
    "    if(time_elaps>time_limit):\n",
    "        frameRate = len(image_frames)/(time_elaps)\n",
    "        break\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "vid.release()\n",
    "#Save video as gif\n",
    "if(len(image_frames)>0):\n",
    "        #Save video as gif\n",
    "        image_frames[0].save('runs/detect/videos/video1.gif',\n",
    "                         save_all=True, optimize=False,\n",
    "                             append_images=image_frames[1:],loop=0)\n",
    "else:\n",
    "    print(\"No image frames to save!\")\n",
    "    \n",
    "print(\"Frame rate: \",frameRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94bc92cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.284113664669919\n"
     ]
    }
   ],
   "source": [
    "print(frameRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6d9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
